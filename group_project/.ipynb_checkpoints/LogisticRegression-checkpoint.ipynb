{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model (JiaLi Yu, Peng Ye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "# Allows plots to appear directly in the notebook.\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read csv file into a dataframe.\n",
    "df = pd.read_csv('processed_data/happiness_data_alan.csv' , keep_default_na=True, sep=',\\s+', delimiter=',', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1344"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                    object\n",
       "year                        int64\n",
       "happiness_score           float64\n",
       "social_support            float64\n",
       "healthy_life_exp_birth    float64\n",
       "life_choices              float64\n",
       "generosity                float64\n",
       "corruption                float64\n",
       "pos_affect                float64\n",
       "neg_affect                float64\n",
       "confidence_gov            float64\n",
       "dem_quality               float64\n",
       "delivery_quality          float64\n",
       "gdp                       float64\n",
       "life_exp_60               float64\n",
       "infant_mortality          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the previous happiness_class from Alan's data set\n",
    "df.drop('happiness_class', axis=1, inplace=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    435\n",
       "6.0    342\n",
       "4.0    260\n",
       "7.0    233\n",
       "3.0     40\n",
       "8.0     34\n",
       "Name: happiness_score, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['happiness_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a116ec7b8>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAECCAYAAADw0Rw8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a116ec390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a barplot for 'Happiness_score' feature \n",
    "df['happiness_score'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above bar plot, we can see that the more closer to the middle happiness score (5.0), the more amount of people there are. To distribute data set into different classifications equally, it is reasonable to separate the 'happiness score' feature into \"high er happiness\"(5.0~8.0) and \"lower happiness\"(3.0~5.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    735\n",
       "1.0    609\n",
       "Name: happiness_class, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness_class = (df['happiness_score'] > 5) * 1.0\n",
    "df_happiness_class = pd.DataFrame({'happiness_class': happiness_class})\n",
    "df_happiness_class['happiness_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the categorical target feature as a numeric feature with only 2 values: 0 (Not happy) or 1 (happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_exp_birth</th>\n",
       "      <th>life_choices</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption</th>\n",
       "      <th>pos_affect</th>\n",
       "      <th>neg_affect</th>\n",
       "      <th>confidence_gov</th>\n",
       "      <th>dem_quality</th>\n",
       "      <th>delivery_quality</th>\n",
       "      <th>gdp</th>\n",
       "      <th>life_exp_60</th>\n",
       "      <th>infant_mortality</th>\n",
       "      <th>happiness_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>0.612072</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>10.297</td>\n",
       "      <td>15.6</td>\n",
       "      <td>70.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>12.066</td>\n",
       "      <td>15.7</td>\n",
       "      <td>68.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>0.299357</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>15.325</td>\n",
       "      <td>15.7</td>\n",
       "      <td>65.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>0.307386</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>17.890</td>\n",
       "      <td>15.8</td>\n",
       "      <td>63.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  social_support  healthy_life_exp_birth  life_choices  \\\n",
       "0  Afghanistan  2008        0.450662               49.209663      0.718114   \n",
       "1  Afghanistan  2009        0.552308               49.624432      0.678896   \n",
       "2  Afghanistan  2010        0.539075               50.008961      0.600127   \n",
       "3  Afghanistan  2011        0.521104               50.367298      0.495901   \n",
       "\n",
       "   generosity  corruption  pos_affect  neg_affect  confidence_gov  \\\n",
       "0    0.181819    0.881686    0.517637    0.258195        0.612072   \n",
       "1    0.203614    0.850035    0.583926    0.237092        0.611545   \n",
       "2    0.137630    0.706766    0.618265    0.275324        0.299357   \n",
       "3    0.175329    0.731109    0.611387    0.267175        0.307386   \n",
       "\n",
       "   dem_quality  delivery_quality     gdp  life_exp_60  infant_mortality  \\\n",
       "0    -1.929690         -1.655084  10.297         15.6              70.8   \n",
       "1    -2.044093         -1.635025  12.066         15.7              68.2   \n",
       "2    -1.991810         -1.617176  15.325         15.7              65.7   \n",
       "3    -1.919018         -1.616221  17.890         15.8              63.3   \n",
       "\n",
       "   happiness_class  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crate a new dataframe where we add column HappinessClass to the original dataframe.\n",
    "df_cross = pd.concat([df, df_happiness_class], axis = 1)\n",
    "# Drop the column RentalPrice from the df_classif dataframe.\n",
    "df_cross.drop('happiness_score', axis=1, inplace=True)\n",
    "df_cross.loc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# According to the analyzing result from Data Understanding, we only pick 8 features from all features. \n",
    "df_cross = df_cross[['happiness_class','social_support', 'healthy_life_exp_birth', 'pos_affect', 'dem_quality', 'delivery_quality', 'life_exp_60', 'infant_mortality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happiness_class           float64\n",
       "social_support            float64\n",
       "healthy_life_exp_birth    float64\n",
       "pos_affect                float64\n",
       "dem_quality               float64\n",
       "delivery_quality          float64\n",
       "life_exp_60               float64\n",
       "infant_mortality          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cross.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the new df into a file for the further usage.\n",
    "df_cross.to_csv(\"processed_data/happiness_class_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept\n",
       "0        1.0\n",
       "1        1.0\n",
       "2        1.0\n",
       "3        1.0\n",
       "4        1.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare an intercept term that adds a 1 to each example.\n",
    "# Scikit-learn does not use an intercept by default.\n",
    "intercept = pd.DataFrame({'Intercept': np.ones(1344)})\n",
    "intercept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the descriptive features\n",
    "# X Descriptive features\n",
    "# y Target feature\n",
    "X = pd.concat([intercept, df_cross[['social_support', 'healthy_life_exp_birth', 'pos_affect', 'dem_quality', 'delivery_quality', 'life_exp_60', 'infant_mortality']]], axis=1)\n",
    "y = df_cross['happiness_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use DataFrame.fillna to fill the nan's directly\n",
    "X = X.fillna(X.mean())\n",
    "y = y.fillna(y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "# Take a third (random) data samples as test data, rest as training data\n",
    "# Note that this training set if very small and the model will not be very reliable due to this sample size problem.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficients on training set: \n",
      " [[-3.56479271  3.14226128 -0.02320625  3.26569265  0.23238677  0.39963547\n",
      "   0.22995058 -0.04590809]]\n"
     ]
    }
   ],
   "source": [
    "# Train on the training set.\n",
    "logreg_train = LogisticRegression().fit(X_train, y_train)\n",
    "# Print the weights learned for each feature.\n",
    "print(\"Coeficients on training set: \\n\", logreg_train.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model (using the model to make predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18644001,  0.81355999],\n",
       "       [ 0.84902606,  0.15097394],\n",
       "       [ 0.46616852,  0.53383148],\n",
       "       [ 0.86141808,  0.13858192],\n",
       "       [ 0.96337465,  0.03662535],\n",
       "       [ 0.26171227,  0.73828773],\n",
       "       [ 0.03068774,  0.96931226],\n",
       "       [ 0.37257892,  0.62742108],\n",
       "       [ 0.38203781,  0.61796219],\n",
       "       [ 0.94841751,  0.05158249]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output = logreg_train.predict_proba(X_train[['Intercept', 'social_support', 'healthy_life_exp_birth', 'pos_affect', 'dem_quality', 'delivery_quality', 'life_exp_60', 'infant_mortality']])\n",
    "# Predicted probabilities for each example. \n",
    "# The output is a pair for each example, \n",
    "# The first component is the probability of the negative class (class 0).\n",
    "# The second component is the probability of the positive class (class 1).\n",
    "train_output[0:10:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 1.  0.  1.  0.  0.  1.  1.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "train_predictions = logreg_train.predict(X_train[['Intercept',\n",
    "                                                  'social_support',\n",
    "                                                  'healthy_life_exp_birth',\n",
    "                                                  'pos_affect', 'dem_quality',\n",
    "                                                  'delivery_quality', 'life_exp_60', 'infant_mortality']])\n",
    "\n",
    "print(\"Predictions: \", train_predictions[0:10:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.81914893617\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy on the training set.  \n",
    "# The accuracy is the ratio of correct predictions to total examples\n",
    "# Total accuracy is then 0.819% accuracy\n",
    "accuracy = logreg_train.score(X_train[['Intercept',\n",
    "                                       'social_support',\n",
    "                                       'healthy_life_exp_birth',\n",
    "                                       'pos_affect',\n",
    "                                       'dem_quality',\n",
    "                                       'delivery_quality',\n",
    "                                       'life_exp_60',\n",
    "                                       'infant_mortality']], y_train)\n",
    "print(\"Accuracy on the training set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.81914893617\n",
      "Confusion matrix: \n",
      " [[420  82]\n",
      " [ 88 350]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.84      0.83       502\n",
      "        1.0       0.81      0.80      0.80       438\n",
      "\n",
      "avg / total       0.82      0.82      0.82       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics.\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_train, train_predictions))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_train, train_predictions))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_train, train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimated classes on test set\n",
    "y_predicted = logreg_train.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.834158415842\n",
      "Confusion matrix: \n",
      " [[203  30]\n",
      " [ 37 134]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.87      0.86       233\n",
      "        1.0       0.82      0.78      0.80       171\n",
      "\n",
      "avg / total       0.83      0.83      0.83       404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics.\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_predicted))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_test, y_predicted))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score (10 times): [ 0.80733945  0.85245902  0.81944444  0.80821918  0.63829787  0.89473684\n",
      "  0.83760684  0.8         0.79674797  0.93103448]\n",
      "accuracy (10 times): [ 0.84444444  0.86666667  0.80740741  0.79259259  0.74814815  0.91044776\n",
      "  0.85820896  0.82835821  0.81343284  0.93984962]\n",
      "precision(10 times): [ 0.91666667  0.85245902  0.71084337  0.69411765  0.90909091  0.96226415\n",
      "  0.875       0.85185185  0.79032258  0.96428571]\n",
      "recall   (10 times): [ 0.72131148  0.85245902  0.96721311  0.96721311  0.49180328  0.83606557\n",
      "  0.80327869  0.75409836  0.80327869  0.9       ]\n",
      "\n",
      "\n",
      "f1-score:  0.797607929590561\n",
      "accuracy:  0.8207499677884595\n",
      "precision: 0.8332368768887232\n",
      "recall:    0.7846721311475411\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using cross-validation\n",
    "# Evaluate the model using 10-fold cross-validation.\n",
    "# Uses 9/10 of data for training and the last 1/10 for testing. \n",
    "# This process is repeated 10 times. More details about cross-validation here: http://www-bcf.usc.edu/~gareth/ISL/\n",
    "scores1 = cross_val_score(LogisticRegression(), X, y, scoring='f1', cv=10)\n",
    "scores2 = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "scores3 = cross_val_score(LogisticRegression(), X, y, scoring='precision', cv=10)\n",
    "scores4 = cross_val_score(LogisticRegression(), X, y, scoring='recall', cv=10)\n",
    "print(\"f1-score (10 times):\", scores_norm1)\n",
    "print(\"accuracy (10 times):\", scores_norm2)\n",
    "print(\"precision(10 times):\", scores_norm3)\n",
    "print(\"recall   (10 times):\", scores_norm4)\n",
    "print(\"\\n\")\n",
    "print(\"f1-score:  {}\".format(scores1.mean()))\n",
    "print(\"accuracy:  {}\".format(scores2.mean()))\n",
    "print(\"precision: {}\".format(scores3.mean()))\n",
    "print(\"recall:    {}\".format(scores4.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise features and retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_exp_birth</th>\n",
       "      <th>pos_affect</th>\n",
       "      <th>dem_quality</th>\n",
       "      <th>delivery_quality</th>\n",
       "      <th>life_exp_60</th>\n",
       "      <th>infant_mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>-1.929690</td>\n",
       "      <td>-1.655084</td>\n",
       "      <td>15.6</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>-2.044093</td>\n",
       "      <td>-1.635025</td>\n",
       "      <td>15.7</td>\n",
       "      <td>68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>-1.991810</td>\n",
       "      <td>-1.617176</td>\n",
       "      <td>15.7</td>\n",
       "      <td>65.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>-1.919018</td>\n",
       "      <td>-1.616221</td>\n",
       "      <td>15.8</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>-1.842996</td>\n",
       "      <td>-1.404078</td>\n",
       "      <td>15.8</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   social_support  healthy_life_exp_birth  pos_affect  dem_quality  \\\n",
       "0        0.450662               49.209663    0.517637    -1.929690   \n",
       "1        0.552308               49.624432    0.583926    -2.044093   \n",
       "2        0.539075               50.008961    0.618265    -1.991810   \n",
       "3        0.521104               50.367298    0.611387    -1.919018   \n",
       "4        0.520637               50.709263    0.710385    -1.842996   \n",
       "\n",
       "   delivery_quality  life_exp_60  infant_mortality  \n",
       "0         -1.655084         15.6              70.8  \n",
       "1         -1.635025         15.7              68.2  \n",
       "2         -1.617176         15.7              65.7  \n",
       "3         -1.616221         15.8              63.3  \n",
       "4         -1.404078         15.8              61.0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For now only work with the continuous features\n",
    "# Same as we did on Linear Regression, we still choose above 7 features for normaliztion\n",
    "df_cont = df_cross[['social_support',\n",
    "                    'healthy_life_exp_birth',\n",
    "                    'pos_affect',\n",
    "                    'dem_quality',\n",
    "                    'delivery_quality',\n",
    "                    'life_exp_60',\n",
    "                    'infant_mortality']]\n",
    "df_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_exp_birth</th>\n",
       "      <th>pos_affect</th>\n",
       "      <th>dem_quality</th>\n",
       "      <th>delivery_quality</th>\n",
       "      <th>life_exp_60</th>\n",
       "      <th>infant_mortality</th>\n",
       "      <th>happiness_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.539623</td>\n",
       "      <td>-0.469795</td>\n",
       "      <td>-0.466070</td>\n",
       "      <td>-0.739972</td>\n",
       "      <td>-0.770344</td>\n",
       "      <td>-0.329114</td>\n",
       "      <td>0.207679</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.248022</td>\n",
       "      <td>-0.447486</td>\n",
       "      <td>-0.237931</td>\n",
       "      <td>-0.797341</td>\n",
       "      <td>-0.760940</td>\n",
       "      <td>-0.316456</td>\n",
       "      <td>0.162304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.285985</td>\n",
       "      <td>-0.426804</td>\n",
       "      <td>-0.119746</td>\n",
       "      <td>-0.771123</td>\n",
       "      <td>-0.752573</td>\n",
       "      <td>-0.316456</td>\n",
       "      <td>0.118674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.337542</td>\n",
       "      <td>-0.407530</td>\n",
       "      <td>-0.143418</td>\n",
       "      <td>-0.734621</td>\n",
       "      <td>-0.752125</td>\n",
       "      <td>-0.303797</td>\n",
       "      <td>0.076789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intercept  social_support  healthy_life_exp_birth  pos_affect  dem_quality  \\\n",
       "0        1.0       -0.539623               -0.469795   -0.466070    -0.739972   \n",
       "1        1.0       -0.248022               -0.447486   -0.237931    -0.797341   \n",
       "2        1.0       -0.285985               -0.426804   -0.119746    -0.771123   \n",
       "3        1.0       -0.337542               -0.407530   -0.143418    -0.734621   \n",
       "\n",
       "   delivery_quality  life_exp_60  infant_mortality  happiness_class  \n",
       "0         -0.770344    -0.329114          0.207679              0.0  \n",
       "1         -0.760940    -0.316456          0.162304              0.0  \n",
       "2         -0.752573    -0.316456          0.118674              0.0  \n",
       "3         -0.752125    -0.303797          0.076789              0.0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will first rescale the descriptive features to ranges [-1,1]\n",
    "# Range normalise all columns to range [-1,1]\n",
    "df_norm = (df_cont - df_cont.min()) / (df_cont.max() - df_cont.min())\n",
    "df_norm = df_norm * 2 - 1\n",
    "# Create a new dataframe df_classif_norm that has all descriptive features rescaled to [-1,1] \n",
    "# and the target feature as in original taking values 0 or 1.\n",
    "\n",
    "df_cross_norm = pd.concat([intercept, df_norm, df_cross.happiness_class], axis=1)\n",
    "df_cross_norm.loc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_norm = pd.concat([intercept, df_cross_norm[['social_support', 'healthy_life_exp_birth', 'pos_affect', 'dem_quality', 'delivery_quality', 'life_exp_60', 'infant_mortality']]], axis=1)\n",
    "y_norm = df_cross_norm['happiness_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use DataFrame.fillna to fill the nan's directly\n",
    "X_norm = X_norm.fillna(X_norm.mean())\n",
    "y_norm = y_norm.fillna(y_norm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y_norm, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficients on normalise training set: \n",
      " [[-1.64999022  3.4907595   2.12386202  1.61789122  0.04366605  0.27201552\n",
      "   2.13456712  0.14808939]]\n"
     ]
    }
   ],
   "source": [
    "# Train on the normalise training set.\n",
    "logreg_train_norm = LogisticRegression().fit(X_train_norm, y_train_norm)\n",
    "# Print the weights learned for each feature.\n",
    "print(\"Coeficients on normalise training set: \\n\", logreg_train_norm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17132683  0.82867317]\n",
      " [ 0.80733659  0.19266341]\n",
      " [ 0.4827746   0.5172254 ]\n",
      " [ 0.93316576  0.06683424]\n",
      " [ 0.98714573  0.01285427]\n",
      " [ 0.12619282  0.87380718]\n",
      " [ 0.01657101  0.98342899]\n",
      " [ 0.1501225   0.8498775 ]\n",
      " [ 0.34676427  0.65323573]\n",
      " [ 0.9928479   0.0071521 ]]\n"
     ]
    }
   ],
   "source": [
    "output_train_norm = logreg_train_norm.predict_proba(X_train_norm[['Intercept', 'social_support', 'healthy_life_exp_birth', 'pos_affect', 'dem_quality', 'delivery_quality', 'life_exp_60', 'infant_mortality']])\n",
    "print(output_train_norm[0:10:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on normalise training set:  [ 1.  0.  1.  0.  0.  1.  1.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "predictions_norm = logreg_train_norm.predict(X_train_norm[['Intercept', 'social_support', 'healthy_life_exp_birth', 'pos_affect', 'dem_quality', 'delivery_quality', 'life_exp_60', 'infant_mortality']])\n",
    "\n",
    "print(\"Predictions on normalise training set: \", predictions_norm[0:10:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.85\n",
      "Confusion matrix: \n",
      " [[436  66]\n",
      " [ 75 363]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.87      0.86       502\n",
      "        1.0       0.85      0.83      0.84       438\n",
      "\n",
      "avg / total       0.85      0.85      0.85       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics.\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_train_norm, predictions_norm))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_train_norm, predictions_norm))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_train_norm, predictions_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94912935,  0.05087065],\n",
       "       [ 0.99151559,  0.00848441],\n",
       "       [ 0.99801176,  0.00198824],\n",
       "       [ 0.90263846,  0.09736154],\n",
       "       [ 0.02965486,  0.97034514],\n",
       "       [ 0.71731645,  0.28268355],\n",
       "       [ 0.19167562,  0.80832438],\n",
       "       [ 0.20522523,  0.79477477],\n",
       "       [ 0.02087737,  0.97912263],\n",
       "       [ 0.01930653,  0.98069347]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation\n",
    "# Estimated class probabilities on test set\n",
    "logreg_train_norm.predict_proba(X_test_norm)[0:10:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated classes on test set\n",
    "y_predicted_norm = logreg_train_norm.predict(X_test_norm)\n",
    "y_predicted_norm[0:10:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.863861386139\n",
      "Confusion matrix: \n",
      " [[204  29]\n",
      " [ 26 145]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.88      0.88       233\n",
      "        1.0       0.83      0.85      0.84       171\n",
      "\n",
      "avg / total       0.86      0.86      0.86       404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some more evaluation metrics.\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_norm, y_predicted_norm))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_test_norm, y_predicted_norm))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_test_norm, y_predicted_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score:  0.8185886090752185\n",
      "accuracy:  0.8409556644513441\n",
      "precision: 0.852690191042994\n",
      "recall:    0.809672131147541\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using cross-validation\n",
    "# Evaluate the model using 10-fold cross-validation.\n",
    "# Uses 9/10 of data for training and the last 1/10 for testing. \n",
    "# This process is repeated 10 times. More details about cross-validation here: http://www-bcf.usc.edu/~gareth/ISL/\n",
    "scores_norm1 = cross_val_score(LogisticRegression(), X_norm, y_norm, scoring='f1', cv=10)\n",
    "scores_norm2 = cross_val_score(LogisticRegression(), X_norm, y_norm, scoring='accuracy', cv=10)\n",
    "scores_norm3 = cross_val_score(LogisticRegression(), X_norm, y_norm, scoring='precision', cv=10)\n",
    "scores_norm4 = cross_val_score(LogisticRegression(), X_norm, y_norm, scoring='recall', cv=10)\n",
    "\n",
    "print(\"f1-score:  {}\".format(scores_norm1.mean()))\n",
    "print(\"accuracy:  {}\".format(scores_norm2.mean()))\n",
    "print(\"precision: {}\".format(scores_norm3.mean()))\n",
    "print(\"recall:    {}\".format(scores_norm4.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Conclusion:\n",
    "    In this section, we have 1344 rows in total from a DataFrame file. We chose 7 continous features to construct the train data set, which were the major features against to target featrue 'happiness score'. Due to that we need the equally distributed sub-groups on happiness score, we categorized the \"happiness score\" into 'higher score' (>5.0) and 'lower score' (<=5.0). Base on this classification, we used Logistric Regression to train the model on both un-normalized dataset and normalized dataset. Finally, we got the prediction model and testing result. It looks that the normalized dataset has the better evaluation result by using cross-validation. Thus, we could train a normalized logistic Regression model for happiness prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
